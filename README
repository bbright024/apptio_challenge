
################
Directory Layout
################

Problem A Solution
.───────────────────────────────────────────────
├── Apptio Infra.pdf         # Coding problem handout
├── Dockerfile		     # Container installation for problem A
├── README			 
├── extra_thoughts.txt       # Ideas/thoughts that didn't fit in README
│
├── configs                  # Go source files for configs pkg
│   ├── configs.go              # Parses json conf files     
│   └── configs_test.go           
│
├── install                  # Scripts for installing if Docker is unavailable
│   ├── configure.sh            # Sets up environment on host machine
│   ├── install.sh	        # Installs logserver on all host machines
│   └── host_info.json	        # Details of all host machines to install logserver on
│
├── logserver		     # Go source files for main pkg
│   ├── logserver.go	        # main() location
│   ├── logserver_test.go	  
│   └── conf.json	        # An example conf file used by main()
│  
├── test                     # Automated testing scripts     
│   ├── small_test.sh           # Runs 'go test' in each project Go pkg
│   ├── medium_test.sh          # Compiles & execs logserver, checking log retrieval
│   └── test_conf.json          # Conf file given to logserver on exec in medium_test
└────────────────────────────────────────────────

#######################
DESIGN & IMPLEMENTATION
#######################



############
ALTERNATIVES
############

 - log.Fatal(http.ListenAndServe(":8080", http.FileServer(http.Dir("/usr/share/doc"))))
     If the log file were used in that http.Dir call, the logserver program would be
     ~10 lines of code.
        -problems:
	   pretty brittle.  If the log file gets large or archived, updates to 
           the logserver would be needed to accomodate changes. However, it's the
	   simplest & quickest solution to the problem we're trying to solve.
	       
- Give every dev root access to the main app host machine
    - Not an option - too many security issues, and could lead to devs installing
      unneeded tools/programs on the machine.

- Modify the kernel by writing a new syscall that takes an inode and tells the kernel
    to never evict that inode's disk blocks from the kernel's internal page cache.
    However, it's doubtful that the log file would ever be evicted anyway, since the
    main app will never close the file descriptor pointing to that inode.
      - problems:
         - Downtime; such a patch would likely require a restart 
         - If the kernel is open-source, non-proprietary, we'd have to fork from
	   the mainline and have continuous maintenance on our new kernel, like
	   how Google maintains Android.  However, we could try to merge our code
	   into the mainline if there
	 - It's possible this is already an option, so we'd need to do some research
	   to make sure we aren't reinventing the wheel
	 - Complexity, time, resources required, and adding kernel code can introduce
	   a great many bugs. 

- Write a caching client proxy server that forwards dev requests.  If all devs go through
   the proxy, there will be a large reduction in CPU, RAM, disk I/O, and network resources
   used by the log server on the main app host machine. 
   - problem:
	It's a little beyond the scope of the problem we're trying to solve, and introduces
	a security vulnerability. Without more information, it's impossible to know if caching
	log files external to the server is allowed. Also, a malicious actor could cover his/her
	tracks by changing values saved in the cache.
      
- Add rsyslog to the main app host machine & copy the log files to an external database
     -problem: 
  	Not enough information is known about the situation.  Rsyslog is more resource
	intensive than my small log server implementation - maybe smaller is better. 

- Add Kerberos to the network & check tickets whenever log files are requested.
   Adding authentication/authorization to the log server would allow for a much
   more dynamic API.  Server admin specific commands could be added, e.g. change configs
   without having to restart the server.
      -problems:
        - increases complexity of the system as a whole
        - Even though main app customers wouldn't need to go through kerb, they might still
	  see slowdowns.  For instance, a dev might write a script that grabs log files every 10 seconds,
	  and overhead of decrypting/encrypting those messages by the server app on the host machine
	  could bog down the system.
	- This is beyond the scope of the main problem - getting the devs access to the log files.
    
- Chmod the log files to a group on the host OS, give that group read privileges,
   give devs an account on the server they can SSH into, and add that account to the group. a cron job
   could be added to the host to add log archive files to that group with read privileges.
     -problems:
         - assumes the security policy is ok with devs having ssh access to the machine.
	 - would be hard to track which dev is using the account and at what time

- Add in a sandbox program to let devs pass in their own functions to filter the log
     -problem:
	complexity.  Something like this would take a long time to build, test, and deploy.
        

###############
DEPLOYMENT PLAN
###############

The deployment plan of the logserver is highly dependent upon the extra
software installed on main app host machine.  For instance, a deployment plan
relying on Docker images would not work if Docker wasn't already installed on
the main app machine, since installing docker while the main app is deployed
could introduce new bugs, security vulnerabilities, and resource utilization
that wasn't planned for.  Thus, any deployment plan should not rely on having
to install new packages.

The deployment also depends upon the infrastructure of the system.  For
example, if the system is fault-tolerant with more than one machine running
the main app, deployment needs to be run on each machine.  Thus, any scripts used
should not assume any specific machine will be the target.

WITHOUT DOCKER:
A deployment plan would need to take these steps:

0. Run unit tests to make sure everything still works
1. Compile a logserver binary that is arch/OS compatible with the main app host machine
   - save a hash value of the binary so we can periodically check the binary in deployment
      to see if it's been modified
2. scp the binary & other relevant files into the same namespace as the log files
3. use ssh [command] to run a script on the main host machine completing these steps:
  a) chmod/chown the binary
    - make sure the server binary isn't root
    - create a group that only the binary & the log files are part of
    - give the group read only privileges to the log files
  b) write either a cron job or a systemd service that adds any new or archived
     log files to the group
  c) have cron or systemd start/restart the server when needed
  d) create a chroot environment for the logserver binary inside the main app log
     directory
  e) add the logserver to a cgroup & limit it's CPU/RAM resource availability
  f) On the gateway machine/router connected to the WAN, modify NAT/port
      forwarding to prevent external logserver access, and/or add a rule to the
      ACL/iptables preventing access from WAN IP's to the port used by the server.
        - note: this would assume devs access the logserver from internal IPs, or
          there is a VPN tunnel setup inside the organization to grant devs internal
          IP addresses
  i) Make sure current user doesn't have root privileges, and execute the server binary
     with "chroot . /logserver"

To run these steps as a bash script, a few details must be known about the target:
  1) IP address
  2) CPU architecture
  3) Kernel version

If there are multiple host machine targets, we could create a JSON file
containing an array of machine data.  The deployment script would parse the
JSON file and run the deployment for each machine.

WITH DOCKER:
1. Create a Dockerfile that
   a) downloads a Go-alpine image
   b) limits resources of the image
   c) links the logfile in as a volume for the logserver
2. Run a script that will scp the Dockerfile
   to the host machine and run it


###########################
MONITORING/REPORTING/ALERTS
###########################

Things to log:
  a) the config file used at runtime
       - the entire file itself, or just a few parameters if too long
  b) request IP origins for each interaction, possibly what they request as well
  c) any errors, of course
  d) could log user agents of the connecting devices, to focus future development
     on a specific hardware/software.  Random, but got the idea from a CMU lecture.
     
Alerts:
  - Send an alert if one IP address is making a ton of requests -
     having the main app be DDOSed by a log server wouldn't be fun to explain to
     clients of the main app.

Monitoring:
  - use heartbeats from an external source to make sure the server is still running.
      In cloud architectures, I think that's what "circuit-breakers" are for, but
      as of 4/12/18 I still don't have a full view. 
      In an old-school deployment, I could set up a cron job that uses netcat or
      some other net suite program to send a HEAD request to the log server.
      If the server didn't respond for a few requests, sound the alarms!  Could
      send a text to a sysadmin.

    Go's logging design makes it easy to have a program's log file be located
on a seperate machine.  Output can be written to a socket, since log.SetOutput
takes an io.Writer interface as the parameter.  To ensure fault tolerance, we
could do a dup system call on the logging file descriptor, causing writes to
occur to both a local file and to the socket file.


#############
CONFIGURATION
#############

One area of parameters to set are cgroup settings:
     maximum memory
allowed, max cpu resources, stuff like that, which would be set in the
Dockerfile.

    There's also monitoring alert settings - where to send alerts, where and how often
to send out heartbeat messages, and trigger levels for auto banning an IP to prevent
DOS attacks.

More program-specific configurations:
 a) port to bind on
 b) if caching is enabled, maximum cache size to be used
 c) location of the main app log file in file system for the log server
 d) location of the logserver config file 
 e) which RPC methods to enable/disable
 f) Datetime format in the main app log: <datetime logtime> - dd/mm/yy, mm/dd/yy, etc.
    - the time pkg in Go has a time.Parse() that needs either the
      RFC number specifying string format, or an example string format.
      Either of these could be specified in configuration.

    Since there's no authentication/authorization of the incoming requests, every
configuration value must be set on execution.  If anyone could change log
server settings via RPC without a/a, the settings would be impossible to keep stable.

#######
TESTING
#######

SMALL TESTS:
    For unit testing the Go code, I followed testing conventions reccomended by
"The Go P.L.".  Table-driven testing makes it easy to check corner cases and
prevents the need to duplicate assertion logic [pg 306].  Running Go unit tests
is also very easy - the "go test" command is much simpler than maintaining a
Makefile for testing C code, and whenever "go test" has a failed test, the
nonzero exit code will halt any bash script.  Code coverage and benchmark
testing are also simple to do with Go tools.

MEDIUM TESTS:
I wrote a bash script that checks the behavior of the logserver during runtime.
The script: 
  1. compiles and runs the logserver
  2. uses curl to make a call to /read on the logserver
  3. displays the log file the server was supposed to read,
      and the results of the call to read.
      
Because my logserver parses the log file, I couldn't use the diff tool to
compare the webpage and the 


To make sure the API worked properly, I ran the logserver on localhost
and in a local Docker container, and used a web browser to access the proper
address:port/uri.  

LARGE TESTS:
Prior to deployment, we need to run the logserver alongside the main app.
We must:
   1)  Confirm that the two apps do not conflict and the logserver has proper
       access to the main app log files
   2)  Ensure the logserver does not slow down the main app when under heavy
       load, and tweak the cgroup settings as needed
   3)  Quantify the logserver's impact on network throughput
         - I've been reading that limiting network bandwidth of a
	   cgroup/container is a tricky issue that hasn't yet been solved.
	   We should still test the impact to get an idea of what might happen
	   if we deployed the logserver.
	   

FURTHER TESTS:
 -  When deployed, use noisy nmap scans from outside the organization to make
      sure the log server port is inaccessible from the WAN.
 -  If the logserver takes queries, could use a fuzzer to try and find query
      strings that cause the program to crash

#########
RESOURCES
#########

For this assignment, I mostly stuck to examples in the Go pkg documentation at
golang.org/pkg/ and examples in "The Go Programming Language".  Staying away
from code frameworks like Gorrilla Mux minimized my tech debt.

Code sources:

 -  Donovan, Alan A. A., and Brian W. Kernighan. "The Go Programming Language".
    New York: Addison-Wesley, 2016.  "The Go Programming Language"

 -  Example code from various packages at golang.org/pkg/*

Scripting help:

 -  https://stackoverflow.com/questions/878600/how-to-create-a-cron-job-using-bash-automatically-without-the-interactive-editor?

 -  Barrett, Daniel J. "Linux Pocket Guide". O'Reilly, 2016.

 -  Frisch, Aileen. "Essential System Administration". O'Reilly, 2002. 

 -  https://github.com/bbright024/proxy-web-server/blob/master/driver.sh
     Simple script for testing web servers, written by Dave O'Halloran of CMU

Idea sources:

 -  MIT 6.858 Security - Lecture 4: Privelege Seperation in Web Apps
     https://www.youtube.com/watch?v=XnBJc3-N2BU

 -  "How to handle configuration in Go"
     https://stackoverflow.com/questions/16465705/how-to-handle-configuration-in-go?

 -  Kubernetes Devs AMA
     https://www.reddit.com/r/kubernetes/comments/8b7f0x/we_are_kubernetes_developers_ask_us_anything/

 -  CMU's 15-418 Parallel Computer Architecture & Programming 2016 - Lecture 14 - Scaling a Website
     https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=3bb2f332-fbdb-4434-9f3b-0c2b3f9668c8
   


   




